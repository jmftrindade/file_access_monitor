{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events of interest from raw instrumentation logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Action</th>\n",
       "      <th>Path</th>\n",
       "      <th>UID</th>\n",
       "      <th>PID</th>\n",
       "      <th>PPID</th>\n",
       "      <th>Command Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1490383121570</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3857</td>\n",
       "      <td>3856</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv in3.csv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1490383121572</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3857</td>\n",
       "      <td>3856</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv in3.csv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1490383121573</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3857</td>\n",
       "      <td>3856</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv in3.csv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1490383121574</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3857</td>\n",
       "      <td>3856</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv in3.csv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1490383121577</td>\n",
       "      <td>write</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3857</td>\n",
       "      <td>3856</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv in3.csv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1490383122914</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3864</td>\n",
       "      <td>3856</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv in3.csv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1490383122916</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3864</td>\n",
       "      <td>3856</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv in3.csv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1490383122917</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3864</td>\n",
       "      <td>3856</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv in3.csv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1490383122918</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3864</td>\n",
       "      <td>3856</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv in3.csv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1490383122922</td>\n",
       "      <td>write</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3864</td>\n",
       "      <td>3856</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv in3.csv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1490383123975</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3871</td>\n",
       "      <td>3856</td>\n",
       "      <td>cp out3.csv out5.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1490383123975</td>\n",
       "      <td>write</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3871</td>\n",
       "      <td>3856</td>\n",
       "      <td>cp out3.csv out5.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1490383124980</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3873</td>\n",
       "      <td>3856</td>\n",
       "      <td>cp out4.csv out6.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1490383124981</td>\n",
       "      <td>write</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3873</td>\n",
       "      <td>3856</td>\n",
       "      <td>cp out4.csv out6.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1490383125986</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3875</td>\n",
       "      <td>3856</td>\n",
       "      <td>cp out5.csv out7.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1490383125986</td>\n",
       "      <td>write</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3875</td>\n",
       "      <td>3856</td>\n",
       "      <td>cp out5.csv out7.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1490383126991</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3877</td>\n",
       "      <td>3856</td>\n",
       "      <td>cp out7.csv out9.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1490383126992</td>\n",
       "      <td>write</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3877</td>\n",
       "      <td>3856</td>\n",
       "      <td>cp out7.csv out9.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time Action                                               Path  \\\n",
       "1   1490383121570   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "3   1490383121572   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "5   1490383121573   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "7   1490383121574   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "10  1490383121577  write  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "12  1490383122914   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "14  1490383122916   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "16  1490383122917   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "18  1490383122918   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "21  1490383122922  write  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "24  1490383123975   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "26  1490383123975  write  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "29  1490383124980   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "31  1490383124981  write  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "34  1490383125986   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "36  1490383125986  write  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "39  1490383126991   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "41  1490383126992  write  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "\n",
       "     UID   PID  PPID                                       Command Line  \n",
       "1   1000  3857  3856  python concat_csvs.py in1.csv in2.csv in3.csv ...  \n",
       "3   1000  3857  3856  python concat_csvs.py in1.csv in2.csv in3.csv ...  \n",
       "5   1000  3857  3856  python concat_csvs.py in1.csv in2.csv in3.csv ...  \n",
       "7   1000  3857  3856  python concat_csvs.py in1.csv in2.csv in3.csv ...  \n",
       "10  1000  3857  3856  python concat_csvs.py in1.csv in2.csv in3.csv ...  \n",
       "12  1000  3864  3856  python concat_csvs.py in1.csv in2.csv in3.csv ...  \n",
       "14  1000  3864  3856  python concat_csvs.py in1.csv in2.csv in3.csv ...  \n",
       "16  1000  3864  3856  python concat_csvs.py in1.csv in2.csv in3.csv ...  \n",
       "18  1000  3864  3856  python concat_csvs.py in1.csv in2.csv in3.csv ...  \n",
       "21  1000  3864  3856  python concat_csvs.py in1.csv in2.csv in3.csv ...  \n",
       "24  1000  3871  3856                              cp out3.csv out5.csv   \n",
       "26  1000  3871  3856                              cp out3.csv out5.csv   \n",
       "29  1000  3873  3856                              cp out4.csv out6.csv   \n",
       "31  1000  3873  3856                              cp out4.csv out6.csv   \n",
       "34  1000  3875  3856                              cp out5.csv out7.csv   \n",
       "36  1000  3875  3856                              cp out5.csv out7.csv   \n",
       "39  1000  3877  3856                              cp out7.csv out9.csv   \n",
       "41  1000  3877  3856                              cp out7.csv out9.csv   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "logs_df = pd.read_csv('loggedfs_events_pagerank_asymmetrical.log')\n",
    "cols = [col for col in logs_df.columns if col in ['Action','Time','Path','PID','PPID','UID','Command Line']]\n",
    "df = logs_df[cols]\n",
    "df[(df['Action'] == 'read') | (df['Action'] == 'write')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Neo4j lineage graph from instrumentation logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lineage_graph as lg\n",
    "\n",
    "graph = lg.build_lineage_graph('loggedfs_events_pagerank_asymmetrical.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom visualization of lineage graph using Vis.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"figure/graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1135c7748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.vis import draw\n",
    "\n",
    "options = {\"Dataset\": \"name\", \"Job\": \"uid\"}\n",
    "draw(graph, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Neo4j temporal lineage graph using Cypher\n",
    "\n",
    "## Query results as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity check query.\n",
    "query = \"\"\"\n",
    "    MATCH (n)-[r]->(m)\n",
    "    RETURN id(n) AS source_id,\n",
    "           id(r) AS rel_id,\n",
    "           id(m) AS target_id\n",
    "\"\"\"\n",
    "\n",
    "results_df = pd.DataFrame(graph.data(query))\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy detection as a reachability query between 2 content similar datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    MATCH (n:Dataset)\n",
    "    WHERE (n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/in1.csv'\n",
    "    OR n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv')\n",
    "    RETURN id(n) as node_id\n",
    "\"\"\"\n",
    "node_ids = graph.data(query)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(a)-[r*]->(b)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from a to b:\\n' % len(paths))\n",
    "print(paths)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(b)-[r*]->(a)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from b to a:\\n' % len(paths))\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy detection as a reachability query between 2 content similar datasets (monotonically increasing edge timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    MATCH (n:Dataset)\n",
    "    WHERE (n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/in1.csv'\n",
    "    OR n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv')\n",
    "    RETURN id(n) as node_id\n",
    "\"\"\"\n",
    "node_ids = graph.data(query)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(a)-[r*]->(b)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    WHERE all(r2 in relationships(p)\n",
    "              where r2.timestamp>=r1.timestamp)    \n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from a to b with monotonically increasing timestamps:\\n' % len(paths))\n",
    "print(paths)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(b)-[r*]->(a)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    WHERE all(r2 in relationships(p)\n",
    "              where r2.timestamp>=r1.timestamp)    \n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from b to a with monotonically increasing timestamps:\\n' % len(paths))\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Aggregate Queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    START from=node(*)\n",
    "    MATCH p=(from)-->(to)\n",
    "    WITH from as from, to as to, count(p) as paths\n",
    "    WHERE paths >= 1\n",
    "    RETURN to,paths\n",
    "\"\"\"\n",
    "\n",
    "paths = graph.data(query)\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 rows affected.\n",
      "\n",
      "Original Nodes:\n",
      "[('275', {'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv', 'labels': ['Dataset']}), ('271', {'name': '/home/lubuntu/src/file_access_monitor/test_workflows/in3.csv', 'labels': ['Dataset']}), ('273', {'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out3.csv', 'labels': ['Dataset']}), ('269', {'labels': ['Job'], 'name': 'python concat_csvs.py in1.csv in2.csv in3.csv in4.csv out3.csv ', 'uid': 'PID=3857,CLI=python concat_csvs.py in1.csv in2.csv in3.csv in4.csv out3.csv ', 'cpu': 100.0, 'pid': 3857}), ('280', {'labels': ['Job'], 'name': 'cp out5.csv out7.csv ', 'uid': 'PID=3875,CLI=cp out5.csv out7.csv ', 'cpu': 100.0, 'pid': 3875}), ('281', {'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out7.csv', 'labels': ['Dataset']}), ('270', {'name': '/home/lubuntu/src/file_access_monitor/test_workflows/in2.csv', 'labels': ['Dataset']}), ('276', {'labels': ['Job'], 'name': 'cp out3.csv out5.csv ', 'uid': 'PID=3871,CLI=cp out3.csv out5.csv ', 'cpu': 100.0, 'pid': 3871}), ('279', {'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out6.csv', 'labels': ['Dataset']}), ('278', {'labels': ['Job'], 'name': 'cp out4.csv out6.csv ', 'uid': 'PID=3873,CLI=cp out4.csv out6.csv ', 'cpu': 100.0, 'pid': 3873}), ('272', {'name': '/home/lubuntu/src/file_access_monitor/test_workflows/in4.csv', 'labels': ['Dataset']}), ('274', {'labels': ['Job'], 'name': 'python concat_csvs.py in1.csv in2.csv in3.csv in4.csv out4.csv ', 'uid': 'PID=3864,CLI=python concat_csvs.py in1.csv in2.csv in3.csv in4.csv out4.csv ', 'cpu': 100.0, 'pid': 3864}), ('268', {'name': '/home/lubuntu/src/file_access_monitor/test_workflows/in1.csv', 'labels': ['Dataset']}), ('277', {'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out5.csv', 'labels': ['Dataset']}), ('282', {'labels': ['Job'], 'name': 'cp out7.csv out9.csv ', 'uid': 'PID=3877,CLI=cp out7.csv out9.csv ', 'cpu': 100.0, 'pid': 3877}), ('283', {'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out9.csv', 'labels': ['Dataset']})]\n",
      "node=275, data={'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv', 'labels': ['Dataset']}\n",
      "node=271, data={'name': '/home/lubuntu/src/file_access_monitor/test_workflows/in3.csv', 'labels': ['Dataset']}\n",
      "node=273, data={'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out3.csv', 'labels': ['Dataset']}\n",
      "node=269, data={'labels': ['Job'], 'name': 'python concat_csvs.py in1.csv in2.csv in3.csv in4.csv out3.csv ', 'uid': 'PID=3857,CLI=python concat_csvs.py in1.csv in2.csv in3.csv in4.csv out3.csv ', 'cpu': 100.0, 'pid': 3857}\n",
      "node=280, data={'labels': ['Job'], 'name': 'cp out5.csv out7.csv ', 'uid': 'PID=3875,CLI=cp out5.csv out7.csv ', 'cpu': 100.0, 'pid': 3875}\n",
      "node=281, data={'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out7.csv', 'labels': ['Dataset']}\n",
      "node=270, data={'name': '/home/lubuntu/src/file_access_monitor/test_workflows/in2.csv', 'labels': ['Dataset']}\n",
      "node=276, data={'labels': ['Job'], 'name': 'cp out3.csv out5.csv ', 'uid': 'PID=3871,CLI=cp out3.csv out5.csv ', 'cpu': 100.0, 'pid': 3871}\n",
      "node=279, data={'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out6.csv', 'labels': ['Dataset']}\n",
      "node=278, data={'labels': ['Job'], 'name': 'cp out4.csv out6.csv ', 'uid': 'PID=3873,CLI=cp out4.csv out6.csv ', 'cpu': 100.0, 'pid': 3873}\n",
      "node=272, data={'name': '/home/lubuntu/src/file_access_monitor/test_workflows/in4.csv', 'labels': ['Dataset']}\n",
      "node=274, data={'labels': ['Job'], 'name': 'python concat_csvs.py in1.csv in2.csv in3.csv in4.csv out4.csv ', 'uid': 'PID=3864,CLI=python concat_csvs.py in1.csv in2.csv in3.csv in4.csv out4.csv ', 'cpu': 100.0, 'pid': 3864}\n",
      "node=268, data={'name': '/home/lubuntu/src/file_access_monitor/test_workflows/in1.csv', 'labels': ['Dataset']}\n",
      "node=277, data={'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out5.csv', 'labels': ['Dataset']}\n",
      "node=282, data={'labels': ['Job'], 'name': 'cp out7.csv out9.csv ', 'uid': 'PID=3877,CLI=cp out7.csv out9.csv ', 'cpu': 100.0, 'pid': 3877}\n",
      "node=283, data={'name': '/home/lubuntu/src/file_access_monitor/test_workflows/out9.csv', 'labels': ['Dataset']}\n",
      "\n",
      "Personalize Vector:\n",
      "{'280': 100.0, '271': 1, '273': 1, '275': 1, '283': 1, '281': 1, '270': 1, '276': 100.0, '279': 1, '278': 100.0, '282': 100.0, '272': 1, '274': 100.0, '268': 1, '277': 1, '269': 100.0}\n",
      "\n",
      "Personalized PageRank:\n",
      "[('269', 0.11009650138283662), ('274', 0.10937734855151436), ('282', 0.08785814083268906), ('280', 0.08496297465565905), ('276', 0.07530329174761789), ('281', 0.07369559043564375), ('278', 0.07160947909945552), ('277', 0.06835979070915303), ('273', 0.05096694695535338), ('275', 0.04927483349215704), ('283', 0.037585966814155554), ('271', 0.03755720677485834), ('270', 0.03755720677485834), ('272', 0.03755720677485834), ('268', 0.03755720677485834), ('279', 0.03068030822433149)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext cypher\n",
    "import networkx as nx\n",
    "import operator\n",
    "%matplotlib inline\n",
    "\n",
    "results = %cypher MATCH p = (a)-[r*]->(b) RETURN p\n",
    "\n",
    "# Networkx graph.\n",
    "g = results.get_graph()\n",
    "\n",
    "#nx.draw(g)\n",
    "#g.nodes(data=True)\n",
    "\n",
    "# Print nodes so that we can see their original ids and properties.\n",
    "print(\"\\nOriginal Nodes:\")\n",
    "print(g.nodes(data=True))\n",
    "\n",
    "# Node weights for personalized pagerank.\n",
    "personalize = {}\n",
    "for node, data in g.nodes(data=True):\n",
    "    if 'Dataset' in data['labels']:\n",
    "        personalize[node] = 1\n",
    "    elif 'Job' in data['labels']:\n",
    "        # Let's weight each edge by the amount of CPU consumed.\n",
    "        personalize[node] = data['cpu']\n",
    "    print(\"node=%s, data=%s\" % (node, data))\n",
    "\n",
    "print(\"\\nPersonalize Vector:\")\n",
    "print(personalize)\n",
    "\n",
    "# Transformation from MultiDigraph to Graph for Pagerank calculation.\n",
    "H = nx.Graph()\n",
    "for src, dst, edge in g.edges(data=True):\n",
    "    # Let's weight each edge by the amount of bytes read / written.\n",
    "    w = edge['data_bytes']\n",
    "    if H.has_edge(src, dst):\n",
    "        H[src][dst]['weight'] += w\n",
    "    else:\n",
    "        H.add_edge(src, dst, weight=w)\n",
    "\n",
    "#print(\"\\nPageRank:\")\n",
    "#print(nx.pagerank(H))\n",
    "\n",
    "print(\"\\nPersonalized PageRank:\")\n",
    "ranks = nx.pagerank(H, personalization=personalize)\n",
    "sorted_ranks = sorted(ranks.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(sorted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
