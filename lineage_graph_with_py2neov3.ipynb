{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events of interest from raw instrumentation logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Action</th>\n",
       "      <th>Path</th>\n",
       "      <th>UID</th>\n",
       "      <th>PID</th>\n",
       "      <th>PPID</th>\n",
       "      <th>Command Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1486075407888</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>17110</td>\n",
       "      <td>17109</td>\n",
       "      <td>cp in1.csv out1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1486075407888</td>\n",
       "      <td>write</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>17110</td>\n",
       "      <td>17109</td>\n",
       "      <td>cp in1.csv out1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1486075408892</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>17112</td>\n",
       "      <td>17109</td>\n",
       "      <td>cat in1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1486075408892</td>\n",
       "      <td>write</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>17112</td>\n",
       "      <td>17109</td>\n",
       "      <td>cat in1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1486075410214</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>17114</td>\n",
       "      <td>17109</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv out3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1486075410215</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>17114</td>\n",
       "      <td>17109</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv out3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1486075410219</td>\n",
       "      <td>write</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>17114</td>\n",
       "      <td>17109</td>\n",
       "      <td>python concat_csvs.py in1.csv in2.csv out3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1486075411282</td>\n",
       "      <td>read</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>17121</td>\n",
       "      <td>17109</td>\n",
       "      <td>cat out3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1486075411283</td>\n",
       "      <td>write</td>\n",
       "      <td>/home/lubuntu/src/file_access_monitor/test_wor...</td>\n",
       "      <td>1000</td>\n",
       "      <td>17121</td>\n",
       "      <td>17109</td>\n",
       "      <td>cat out3.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time Action                                               Path  \\\n",
       "2   1486075407888   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "4   1486075407888  write  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "7   1486075408892   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "9   1486075408892  write  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "11  1486075410214   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "13  1486075410215   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "16  1486075410219  write  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "19  1486075411282   read  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "21  1486075411283  write  /home/lubuntu/src/file_access_monitor/test_wor...   \n",
       "\n",
       "     UID    PID   PPID                                     Command Line  \n",
       "2   1000  17110  17109                             cp in1.csv out1.csv   \n",
       "4   1000  17110  17109                             cp in1.csv out1.csv   \n",
       "7   1000  17112  17109                                     cat in1.csv   \n",
       "9   1000  17112  17109                                     cat in1.csv   \n",
       "11  1000  17114  17109  python concat_csvs.py in1.csv in2.csv out3.csv   \n",
       "13  1000  17114  17109  python concat_csvs.py in1.csv in2.csv out3.csv   \n",
       "16  1000  17114  17109  python concat_csvs.py in1.csv in2.csv out3.csv   \n",
       "19  1000  17121  17109                                    cat out3.csv   \n",
       "21  1000  17121  17109                                    cat out3.csv   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "logs_df = pd.read_csv('loggedfs_events4.log')\n",
    "cols = [col for col in logs_df.columns if col in ['Action','Time','Path','PID','PPID','UID','Command Line']]\n",
    "df = logs_df[cols]\n",
    "df[(df['Action'] == 'read') | (df['Action'] == 'write')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Neo4j lineage graph from instrumentation logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lineage_graph as lg\n",
    "\n",
    "graph = lg.build_lineage_graph('loggedfs_events4.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom visualization of lineage graph using Vis.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"figure/graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x11373cbe0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.vis import draw\n",
    "\n",
    "options = {\"Dataset\": \"name\", \"Job\": \"uid\"}\n",
    "draw(graph, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Neo4j temporal lineage graph using Cypher\n",
    "\n",
    "## Query results as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rel_id  source_id  target_id\n",
      "0     500        591        596\n",
      "1     498        591        594\n",
      "2     496        591        592\n",
      "3     497        592        593\n",
      "4     499        594        595\n",
      "5     502        596        598\n",
      "6     501        597        596\n",
      "7     503        598        599\n",
      "8     504        599        600\n"
     ]
    }
   ],
   "source": [
    "# Sanity check query.\n",
    "query = \"\"\"\n",
    "    MATCH (n)-[r]->(m)\n",
    "    RETURN id(n) AS source_id,\n",
    "           id(r) AS rel_id,\n",
    "           id(m) AS target_id\n",
    "\"\"\"\n",
    "\n",
    "results_df = pd.DataFrame(graph.data(query))\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy detection as a reachability query between 2 content similar datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 1 path(s) from a to b:\n",
      "\n",
      "[{'b.name': '/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv', 'p': (f944c12)-[:IS_READ_BY {timestamp:1486075410214}]->(c1f4d7f)-[:WRITES_TO {timestamp:1486075410219}]->(`/home/lubuntu/src/file_access_monitor/test_workflows/out3.csv`)-[:IS_READ_BY {timestamp:1486075411282}]->(d4bb19c)-[:WRITES_TO {timestamp:1486075411283}]->(`/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv`)}]\n",
      "\n",
      "Found 0 path(s) from b to a:\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    MATCH (n:Dataset)\n",
    "    WHERE (n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/in1.csv'\n",
    "    OR n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv')\n",
    "    RETURN id(n) as node_id\n",
    "\"\"\"\n",
    "node_ids = graph.data(query)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(a)-[r*]->(b)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from a to b:\\n' % len(paths))\n",
    "print(paths)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(b)-[r*]->(a)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from b to a:\\n' % len(paths))\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy detection as a reachability query between 2 content similar datasets (monotonically increasing edge timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 1 path(s) from a to b with monotonically increasing timestamps:\n",
      "\n",
      "[{'b.name': '/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv', 'p': (f944c12)-[:IS_READ_BY {timestamp:1486075410214}]->(c1f4d7f)-[:WRITES_TO {timestamp:1486075410219}]->(`/home/lubuntu/src/file_access_monitor/test_workflows/out3.csv`)-[:IS_READ_BY {timestamp:1486075411282}]->(d4bb19c)-[:WRITES_TO {timestamp:1486075411283}]->(`/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv`)}]\n",
      "\n",
      "Found 0 path(s) from b to a with monotonically increasing timestamps:\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    MATCH (n:Dataset)\n",
    "    WHERE (n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/in1.csv'\n",
    "    OR n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv')\n",
    "    RETURN id(n) as node_id\n",
    "\"\"\"\n",
    "node_ids = graph.data(query)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(a)-[r*]->(b)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    WHERE all(r2 in relationships(p)\n",
    "              where r2.timestamp>=r1.timestamp)    \n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from a to b with monotonically increasing timestamps:\\n' % len(paths))\n",
    "print(paths)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(b)-[r*]->(a)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    WHERE all(r2 in relationships(p)\n",
    "              where r2.timestamp>=r1.timestamp)    \n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from b to a with monotonically increasing timestamps:\\n' % len(paths))\n",
    "print(paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
