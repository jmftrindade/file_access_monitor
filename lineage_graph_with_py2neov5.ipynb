{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Events of interest from raw instrumentation logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Action</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f1e22a0-440b-4d9a-8b5b-6963ee86da82</td>\n",
       "      <td>read</td>\n",
       "      <td>6f57ebb7-0e27-4503-a4b8-978c251c14b5</td>\n",
       "      <td>4/4/2016 1:55:47 AM</td>\n",
       "      <td>4/4/2016 1:55:50 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c9f76f52-12e8-4aee-9061-748e13b956e2</td>\n",
       "      <td>read</td>\n",
       "      <td>5719e9da-7f82-470d-bd23-d8ca873f3ea6</td>\n",
       "      <td>4/4/2016 3:11:44 PM</td>\n",
       "      <td>4/4/2016 3:12:44 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1c6abfe-a83b-4a31-b112-ed3c9a2b31f4</td>\n",
       "      <td>read</td>\n",
       "      <td>34bae790-b5fc-4f8e-a7d0-1db41f4a11df</td>\n",
       "      <td>4/4/2016 3:18:39 PM</td>\n",
       "      <td>4/4/2016 3:18:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e0b386e-689b-42e4-acbe-6ee9f0f12dd6</td>\n",
       "      <td>read</td>\n",
       "      <td>0005d127-8a26-4964-a217-84254ac15787</td>\n",
       "      <td>4/4/2016 1:06:07 PM</td>\n",
       "      <td>4/4/2016 1:10:53 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dba194b3-151a-4fa7-b1a7-773f2523b592</td>\n",
       "      <td>read</td>\n",
       "      <td>14c13e05-0dac-4139-a981-8955c99b5234</td>\n",
       "      <td>4/4/2016 5:53:25 AM</td>\n",
       "      <td>4/4/2016 5:53:35 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Job Action  \\\n",
       "0  5f1e22a0-440b-4d9a-8b5b-6963ee86da82   read   \n",
       "1  c9f76f52-12e8-4aee-9061-748e13b956e2   read   \n",
       "2  a1c6abfe-a83b-4a31-b112-ed3c9a2b31f4   read   \n",
       "3  8e0b386e-689b-42e4-acbe-6ee9f0f12dd6   read   \n",
       "4  dba194b3-151a-4fa7-b1a7-773f2523b592   read   \n",
       "\n",
       "                                Dataset            StartTime  \\\n",
       "0  6f57ebb7-0e27-4503-a4b8-978c251c14b5  4/4/2016 1:55:47 AM   \n",
       "1  5719e9da-7f82-470d-bd23-d8ca873f3ea6  4/4/2016 3:11:44 PM   \n",
       "2  34bae790-b5fc-4f8e-a7d0-1db41f4a11df  4/4/2016 3:18:39 PM   \n",
       "3  0005d127-8a26-4964-a217-84254ac15787  4/4/2016 1:06:07 PM   \n",
       "4  14c13e05-0dac-4139-a981-8955c99b5234  4/4/2016 5:53:25 AM   \n",
       "\n",
       "               EndTime  \n",
       "0  4/4/2016 1:55:50 AM  \n",
       "1  4/4/2016 3:12:44 PM  \n",
       "2  4/4/2016 3:18:59 PM  \n",
       "3  4/4/2016 1:10:53 PM  \n",
       "4  4/4/2016 5:53:35 AM  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('lineage_edges_1000.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Build a Neo4j lineage graph from instrumentation logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import lineage_graph_cosmos as lg\n",
    "\n",
    "graph = lg.build_lineage_graph('lineage_edges_1000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Custom visualization of lineage graph using Vis.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scripts.vis import draw\n",
    "\n",
    "options = {\"Dataset\": \"name\", \"Job\": \"uid\"}\n",
    "draw(graph, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Query Neo4j temporal lineage graph using Cypher\n",
    "\n",
    "## Query results as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity check query.\n",
    "query = \"\"\"\n",
    "    MATCH (n)-[r]->(m)\n",
    "    RETURN id(n) AS source_id,\n",
    "           id(r) AS rel_id,\n",
    "           id(m) AS target_id\n",
    "\"\"\"\n",
    "\n",
    "results_df = pd.DataFrame(graph.data(query))\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Copy detection as a reachability query between 2 content similar datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    MATCH (n:Dataset)\n",
    "    WHERE (n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/in1.csv'\n",
    "    OR n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv')\n",
    "    RETURN id(n) as node_id\n",
    "\"\"\"\n",
    "node_ids = graph.data(query)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(a)-[r*]->(b)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from a to b:\\n' % len(paths))\n",
    "print(paths)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(b)-[r*]->(a)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from b to a:\\n' % len(paths))\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Copy detection as a reachability query between 2 content similar datasets (monotonically increasing edge timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    MATCH (n:Dataset)\n",
    "    WHERE (n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/in1.csv'\n",
    "    OR n.name = '/home/lubuntu/src/file_access_monitor/test_workflows/out4.csv')\n",
    "    RETURN id(n) as node_id\n",
    "\"\"\"\n",
    "node_ids = graph.data(query)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(a)-[r*]->(b)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    WHERE all(r2 in relationships(p)\n",
    "              where r2.timestamp>=r1.timestamp)    \n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from a to b with monotonically increasing timestamps:\\n' % len(paths))\n",
    "print(paths)\n",
    "\n",
    "# Path query with monotonically increasing timestamps.\n",
    "query = \"\"\"\n",
    "    START a=node(%d), b=node(%d)\n",
    "    MATCH p=(b)-[r*]->(a)\n",
    "    WITH head(relationships(p)) as r1, p, b\n",
    "    WHERE all(r2 in relationships(p)\n",
    "              where r2.timestamp>=r1.timestamp)    \n",
    "    RETURN p, b.name\n",
    "\"\"\" % (node_ids[0]['node_id'], node_ids[1]['node_id'])\n",
    "\n",
    "\n",
    "paths = graph.data(query)\n",
    "print('\\nFound %d path(s) from b to a with monotonically increasing timestamps:\\n' % len(paths))\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext cypher\n",
    "import networkx as nx\n",
    "import operator\n",
    "%matplotlib inline\n",
    "\n",
    "results = %cypher MATCH p = (a)-[r*]->(b) RETURN p\n",
    "\n",
    "# Networkx graph.\n",
    "g = results.get_graph()\n",
    "\n",
    "#nx.draw(g)\n",
    "#g.nodes(data=True)\n",
    "\n",
    "# Print nodes so that we can see their original ids and properties.\n",
    "print(\"\\nOriginal Nodes:\")\n",
    "print(g.nodes(data=True))\n",
    "\n",
    "# Node weights for personalized pagerank.\n",
    "personalize = {}\n",
    "for node, data in g.nodes(data=True):\n",
    "    if 'Dataset' in data['labels']:\n",
    "        personalize[node] = 1\n",
    "    elif 'Job' in data['labels']:\n",
    "        # Let's weight each edge by the amount of CPU consumed.\n",
    "        personalize[node] = data['cpu']\n",
    "    print(\"node=%s, data=%s\" % (node, data))\n",
    "\n",
    "print(\"\\nPersonalize Vector:\")\n",
    "print(personalize)\n",
    "\n",
    "# Transformation from MultiDigraph to Graph for Pagerank calculation.\n",
    "H = nx.Graph()\n",
    "for src, dst, edge in g.edges(data=True):\n",
    "    # Let's weight each edge by the amount of bytes read / written.\n",
    "    w = edge['data_bytes']\n",
    "    if H.has_edge(src, dst):\n",
    "        H[src][dst]['weight'] += w\n",
    "    else:\n",
    "        H.add_edge(src, dst, weight=w)\n",
    "\n",
    "#print(\"\\nPageRank:\")\n",
    "#print(nx.pagerank(H))\n",
    "\n",
    "print(\"\\nPersonalized PageRank:\")\n",
    "ranks = nx.pagerank(H, personalization=personalize)\n",
    "sorted_ranks = sorted(ranks.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(sorted_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Lineage Temporal Graph (Cosmos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load 1000 rows into a neo4j graph: 10153 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from py2neo import Graph\n",
    "\n",
    "# Uncomment this to cleanup all existing graphs.\n",
    "#query = \"\"\"\n",
    "#MATCH (n)\n",
    "#WITH n limit 100000\n",
    "#DETACH DELETE n;  \n",
    "#\"\"\"\n",
    "#graph = Graph()\n",
    "#graph.data(query)\n",
    "\n",
    "pwd = os.getcwd()\n",
    "num_rows = 1000  # Edit this to pick the correct file.\n",
    "filename = 'file:///%s/lineage_edges_%s.csv' % (pwd, num_rows)\n",
    "\n",
    "# Load CSV into a neo4j graph.\n",
    "query = \"\"\"\n",
    "USING PERIODIC COMMIT \n",
    "LOAD CSV WITH HEADERS FROM '%s'\n",
    "  AS line\n",
    "  FIELDTERMINATOR ','\n",
    "MERGE (src:Job { id: line.Job, name: line.Job, uid: line.Job })\n",
    "MERGE (dst:Dataset { id: line.Dataset, name: line.Dataset })\n",
    "FOREACH(t in CASE WHEN line.Action='read' THEN [1] ELSE [] END |\n",
    "    CREATE (src)-[:READS_FROM {time: line.StartTime}]->(dst))\n",
    "FOREACH(t in CASE WHEN line.Action='write' THEN [1] ELSE [] END |\n",
    "    CREATE (src)-[:WRITES_TO {time: line.StartTime}]->(dst))\n",
    "\"\"\" % filename\n",
    "graph = Graph()\n",
    "graph.delete_all()\n",
    "\n",
    "t0 = int(round(time.time() * 1000))\n",
    "graph.data(query)\n",
    "t1 = int(round(time.time() * 1000))\n",
    "print('Time to load %s rows into a neo4j graph: %s ms' % (num_rows, (t1 - t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"figure/graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x114258ba8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.vis import draw\n",
    "\n",
    "options = {\"Dataset\": \"name\", \"Job\": \"uid\"}\n",
    "draw(graph, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pagerank and other algos using networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "num_hops = 3\n",
    "query = \"\"\"\n",
    "    MATCH p=(n)-[r:SENT_EMAIL_TO*%s]->(m)\n",
    "    RETURN p\n",
    "\"\"\" % num_hops\n",
    "\n",
    "t0 = int(round(time.time() * 1000))\n",
    "motifs = graph.data(query)\n",
    "t1 = int(round(time.time() * 1000))\n",
    "\n",
    "print('Time to find %s-hop motifs: %s ms' % (num_hops, (t1 - t0)))\n",
    "#print('%s-hop motifs: %s' % (motifs, num_hops))\n",
    "\n",
    "%load_ext cypher\n",
    "import networkx as nx\n",
    "import operator\n",
    "%matplotlib inline\n",
    "\n",
    "# Networkx graph.\n",
    "t0 = int(round(time.time() * 1000))\n",
    "results = %cypher MATCH p = (a)-[r]->(b) RETURN p\n",
    "g = results.get_graph()\n",
    "#nx.draw(g)\n",
    "g.nodes(data=True)\n",
    "t1 = int(round(time.time() * 1000))\n",
    "print('Time to load it into a networkx graph: %s ms' % (t1 - t0))\n",
    "\n",
    "t0 = int(round(time.time() * 1000))\n",
    "#print('In-degree: %s' % g.in_degree())\n",
    "t1 = int(round(time.time() * 1000))\n",
    "print('Time to compute in-degree: %s ms' % (t1 - t0))\n",
    "\n",
    "t0 = int(round(time.time() * 1000))       \n",
    "centrality = nx.betweenness_centrality(g)\n",
    "#print('Centrality: %s' % centrality)\n",
    "t1 = int(round(time.time() * 1000))       \n",
    "print('Time to compute betweeness centrality: %s ms' % (t1 - t0))\n",
    "\n",
    "\n",
    "# Print nodes so that we can see their original ids and properties.\n",
    "#print(\"\\nOriginal Nodes:\")\n",
    "#print(g.nodes(data=True))\n",
    "\n",
    "# Node weights for personalized pagerank.\n",
    "t0 = int(round(time.time() * 1000))\n",
    "personalize = {}\n",
    "for node, data in g.nodes(data=True):\n",
    "    if 'Person' in data['labels']:\n",
    "        personalize[node] = 1\n",
    "    #print(\"node=%s, data=%s\" % (node, data))\n",
    "t1 = int(round(time.time() * 1000))\n",
    "print('Time to create PageRank personalization vector: %s ms' % (t1 - t0))\n",
    "\n",
    "    \n",
    "#print(\"\\nPersonalize Vector:\")\n",
    "#print(personalize)\n",
    "\n",
    "# Transformation from MultiDigraph to Graph for Pagerank calculation.\n",
    "t0 = int(round(time.time() * 1000))\n",
    "H = nx.Graph()\n",
    "for src, dst, edge in g.edges(data=True):\n",
    "    # Let's weight each edge by the amount of bytes read / written.\n",
    "    w = int(edge['time'])\n",
    "    if H.has_edge(src, dst):\n",
    "        H[src][dst]['weight'] += w\n",
    "    else:\n",
    "        H.add_edge(src, dst, weight=w)\n",
    "t1 = int(round(time.time() * 1000))\n",
    "print('Time to convert from MultiDigraph to Graph for PageRank calculation: %s ms' % (t1 - t0))\n",
    "\n",
    "\n",
    "t0 = int(round(time.time() * 1000))       \n",
    "ranks = nx.pagerank(H, personalization=personalize)\n",
    "sorted_ranks = sorted(ranks.items(), key=operator.itemgetter(1), reverse=True)\n",
    "t1 = int(round(time.time() * 1000))\n",
    "print('Time to compute Pagerank: %s ms' % (t1 - t0))\n",
    "\n",
    "#print(\"\\nPersonalized PageRank:\")\n",
    "#print(sorted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
